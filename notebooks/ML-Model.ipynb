{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e843662c",
   "metadata": {},
   "source": [
    "# ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c11b1758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "855287ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pelosi airplane landed safely taiwan amp playi...</td>\n",
       "      <td>1</td>\n",
       "      <td>pelosi</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hobipalooza laacademiaexpulsion weuro jhopeatl...</td>\n",
       "      <td>1</td>\n",
       "      <td>hobipalooza</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v intro logo animation blue smoke looking prof...</td>\n",
       "      <td>1</td>\n",
       "      <td>yk</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>youre missing shes far taiwan couplegoals http...</td>\n",
       "      <td>0</td>\n",
       "      <td>taiwan</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>twitter make laugh scared pelosi taiwan visit</td>\n",
       "      <td>1</td>\n",
       "      <td>pelosi</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  sentiment     hashtags  \\\n",
       "0  pelosi airplane landed safely taiwan amp playi...          1       pelosi   \n",
       "1  hobipalooza laacademiaexpulsion weuro jhopeatl...          1  hobipalooza   \n",
       "2  v intro logo animation blue smoke looking prof...          1           yk   \n",
       "3  youre missing shes far taiwan couplegoals http...          0       taiwan   \n",
       "4      twitter make laugh scared pelosi taiwan visit          1       pelosi   \n",
       "\n",
       "  lang  \n",
       "0   en  \n",
       "1   en  \n",
       "2   en  \n",
       "3   en  \n",
       "4   en  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "model_tweets = pd.read_csv('../data/model_ready_data.csv')\n",
    "model_tweets = model_tweets.fillna(\"\")\n",
    "model_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5be2b034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3945, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d83974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4492 1925\n",
    "sentiment_analysis_tweet_data = model_tweets.copy(deep=True)\n",
    "sentiment_analysis_tweet_data.drop(sentiment_analysis_tweet_data[sentiment_analysis_tweet_data['sentiment'] == -1].index, inplace=True)\n",
    "sentiment_analysis_tweet_data.reset_index(drop=True, inplace=True)\n",
    "tweet_train = sentiment_analysis_tweet_data.iloc[:4492,]\n",
    "tweet_test = sentiment_analysis_tweet_data.iloc[4493:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0c91139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from joblib import dump, load # used for saving and loading sklearn objects\n",
    "from scipy.sparse import save_npz, load_npz # used for saving and loading sparse matrices\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9851073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_vectorizer = CountVectorizer(ngram_range=(1, 1))\n",
    "unigram_vectorizer.fit(tweet_train['full_text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a0cc506",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unigram = unigram_vectorizer.transform(tweet_train['full_text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e54f478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_tf_idf_transformer = TfidfTransformer()\n",
    "unigram_tf_idf_transformer.fit(X_train_unigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5a053e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unigram_tf_idf = unigram_tf_idf_transformer.transform(X_train_unigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72506181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(ngram_range=(1, 2))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "bigram_vectorizer.fit(tweet_train['full_text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "316c9ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bigram = bigram_vectorizer.transform(tweet_train['full_text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8212eb5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_tf_idf_transformer = TfidfTransformer()\n",
    "bigram_tf_idf_transformer.fit(X_train_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c8a2f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bigram_tf_idf = bigram_tf_idf_transformer.transform(X_train_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5fd0128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2178053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_show_scores(X: csr_matrix, y: np.array, title: str) -> None:\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X, y,train_size=0.75, stratify=y\n",
    "    )\n",
    "\n",
    "    clf = SGDClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_score = clf.score(X_train, y_train)\n",
    "    valid_score = clf.score(X_valid, y_valid)\n",
    "\n",
    "    global_vars = globals()\n",
    "    if(valid_score > global_vars['best_score']):\n",
    "        global_vars['best_model'] = clf\n",
    "        global_vars['best_model_name'] = title\n",
    "        global_vars['best_score'] = valid_score\n",
    "\n",
    "    print(f'{title}\\nTrain score: {round(train_score, 2)} ; Validation score: {round(valid_score, 2)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "862f6083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = tweet_train['sentiment'].values\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a74f9b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Counts\n",
      "Train score: 1.0 ; Validation score: 0.86\n",
      "\n",
      "Unigram Tf-Idf\n",
      "Train score: 1.0 ; Validation score: 0.86\n",
      "\n",
      "Bigram Counts\n",
      "Train score: 1.0 ; Validation score: 0.85\n",
      "\n",
      "Bigram Tf-Idf\n",
      "Train score: 1.0 ; Validation score: 0.86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model = \"\"\n",
    "best_model_name = \"\"\n",
    "best_score = 0\n",
    "\n",
    "train_and_show_scores(X_train_unigram, y_train, 'Unigram Counts')\n",
    "train_and_show_scores(X_train_unigram_tf_idf, y_train, 'Unigram Tf-Idf')\n",
    "train_and_show_scores(X_train_bigram, y_train, 'Bigram Counts')\n",
    "train_and_show_scores(X_train_bigram_tf_idf, y_train, 'Bigram Tf-Idf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb26614f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best Model is Unigram Tf-Idf with a Validation score of: 0.86\n"
     ]
    }
   ],
   "source": [
    "print(f'The best Model is {best_model_name} with a Validation score of: {round(best_score, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54819b76",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "914e9d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/abel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a501b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as  pd\n",
    "from pprint import pprint\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import spacy\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8cf01fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f79cbbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pelosi airplane landed safely taiwan amp playi...</td>\n",
       "      <td>1</td>\n",
       "      <td>pelosi</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hobipalooza laacademiaexpulsion weuro jhopeatl...</td>\n",
       "      <td>1</td>\n",
       "      <td>hobipalooza</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v intro logo animation blue smoke looking prof...</td>\n",
       "      <td>1</td>\n",
       "      <td>yk</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>youre missing shes far taiwan couplegoals http...</td>\n",
       "      <td>0</td>\n",
       "      <td>taiwan</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>twitter make laugh scared pelosi taiwan visit</td>\n",
       "      <td>1</td>\n",
       "      <td>pelosi</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3940</th>\n",
       "      <td>american aggression stopped america wants war ...</td>\n",
       "      <td>0</td>\n",
       "      <td>taiwan</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3941</th>\n",
       "      <td>america bully always instigates aggression mc ...</td>\n",
       "      <td>1</td>\n",
       "      <td>pelosi</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3942</th>\n",
       "      <td>sudans military coup regime supported russias ...</td>\n",
       "      <td>1</td>\n",
       "      <td>sudan</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3943</th>\n",
       "      <td>download youtube golden v apk android devices ...</td>\n",
       "      <td>1</td>\n",
       "      <td>youtube</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3944</th>\n",
       "      <td>us china china sea playing mean game battleshi...</td>\n",
       "      <td>0</td>\n",
       "      <td>taiwanstraitscrisis</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3945 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              full_text  sentiment  \\\n",
       "0     pelosi airplane landed safely taiwan amp playi...          1   \n",
       "1     hobipalooza laacademiaexpulsion weuro jhopeatl...          1   \n",
       "2     v intro logo animation blue smoke looking prof...          1   \n",
       "3     youre missing shes far taiwan couplegoals http...          0   \n",
       "4         twitter make laugh scared pelosi taiwan visit          1   \n",
       "...                                                 ...        ...   \n",
       "3940  american aggression stopped america wants war ...          0   \n",
       "3941  america bully always instigates aggression mc ...          1   \n",
       "3942  sudans military coup regime supported russias ...          1   \n",
       "3943  download youtube golden v apk android devices ...          1   \n",
       "3944  us china china sea playing mean game battleshi...          0   \n",
       "\n",
       "                 hashtags lang  \n",
       "0                  pelosi   en  \n",
       "1             hobipalooza   en  \n",
       "2                      yk   en  \n",
       "3                  taiwan   en  \n",
       "4                  pelosi   en  \n",
       "...                   ...  ...  \n",
       "3940               taiwan   en  \n",
       "3941               pelosi   en  \n",
       "3942                sudan   en  \n",
       "3943              youtube   en  \n",
       "3944  taiwanstraitscrisis   en  \n",
       "\n",
       "[3945 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model_data = model_tweets.copy(deep=True)\n",
    "topic_model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70e8c62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hastags_words_list():\n",
    "    hashtagList = []\n",
    "    for hashtags in topic_model_data.hashtags:\n",
    "        if(hashtags != \"\"):\n",
    "            hashtagList += hashtags.split(',')\n",
    "\n",
    "    return hashtagList\n",
    "\n",
    "hashtag = get_hastags_words_list()\n",
    "\n",
    "data = [word for sentence in topic_model_data.full_text for word in sentence.split(' ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ee95e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pelosi', 'hobipalooza', 'yk', 'taiwan', 'pelosi']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtag[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04f59a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pelosi',\n",
       " 'airplane',\n",
       " 'landed',\n",
       " 'safely',\n",
       " 'taiwan',\n",
       " 'amp',\n",
       " 'playing',\n",
       " 'win',\n",
       " 'win',\n",
       " 'financial']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d0818d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pelosi', 'airplane', 'landed', 'safely', 'taiwan']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_words = data + hashtag\n",
    "data_words = [word for word in data_words if word != '']\n",
    "data_words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6d568b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p', 'e', 'l', 'o', 's', 'i']\n"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
